{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7723413f-5d4a-484f-a09f-293c7fdcb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import math\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "plt.style.use(astropy_mpl_style)\n",
    "import scipy.optimize as op\n",
    "import matplotlib as mpl\n",
    "from astropy.table import Table\n",
    "import matplotlib.gridspec as gridspec\n",
    "from astropy.io import fits\n",
    "from numpy import full, nan\n",
    "from traceback_functions import lnlikeV, lnpriorV, lnprobV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fc3b8c-69a5-4fff-8993-648f88bad868",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul = fits.open('all_OBA.fits')\n",
    "hdul = hdul[1].data\n",
    "t = Table(hdul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acf8166-14b6-4a43-be58-3adbf04d95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = t['ra']\n",
    "dec = t['dec']\n",
    "l = t['l']\n",
    "b = t['b']\n",
    "Plx = t['plx']\n",
    "ePlx = t['e_plx']\n",
    "pmRA = t['pmra_1']\n",
    "pmDE = t['pmde_1']\n",
    "epmRA = t['e_pmra_1']\n",
    "epmDE = t['e_pmde_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce1f49e-3c0d-484f-9036-b9470f619e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define central RA, Dec, l, b, proper motions, cluster distance, cluster RV\n",
    "\n",
    "Lc= 265.08\n",
    "Bc= 1.4\n",
    "Dcluster = 1000\n",
    "RVc50 = -20.75\n",
    "RVc84, RVc16 = 20.12, -0.418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb634bd7-c8e2-4f14-8cb5-f27d49253adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.array([-0.0548755604162154,-0.8734370902348850,-0.4838350155487132,0.4941094278755837,-0.4448296299600112,0.7469822444972189,-0.8676661490190047,-0.1980763734312015,0.4559837761750669]).reshape(3,3)\n",
    "k = 4.74057\n",
    "Tinv = np.linalg.inv(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "160aa88e-fc69-4561-a674-4855a64c9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ra)  \n",
    "traceback_indices = [] \n",
    "vLcorr=[]\n",
    "vBcorr=[]\n",
    "vLcorr_p=[]\n",
    "vBcorr_p=[]\n",
    "vLcorr_n=[]\n",
    "vBcorr_n=[]\n",
    "PMRA_=[]\n",
    "PMDEC_=[]\n",
    "EPMRA_=[]\n",
    "EPMDEC_=[]\n",
    "PARALLAXES_=[]\n",
    "PML=[]\n",
    "PMB=[]\n",
    "\n",
    "for idx in range(0,len(ra)):\n",
    "    \n",
    "    #################### Here you may choose only to perform the transformation on sources with reliable astrometry with an 'if' statement  #############\n",
    "    \n",
    "    # if ruwe[idx] < 1.4 and prob[idx]>0.89 and CGcluster[idx] == name and np.isnan(Gmag[idx])==False:\n",
    "        Ra = np.deg2rad(ra[idx])\n",
    "        DEC = np.deg2rad(dec[idx])\n",
    "        L = np.deg2rad(l[idx])\n",
    "        B = np.deg2rad(b[idx])\n",
    "        PLX = Plx[idx]\n",
    "        EPLX = ePlx[idx]\n",
    "        PMRA = pmRA[idx]\n",
    "        PMDEC = pmDE[idx]\n",
    "        EPMRA = epmRA[idx]\n",
    "        EPMDEC = epmDE[idx]\n",
    "        PMRA_.append(PMRA)\n",
    "        PMDEC_.append(PMDEC)\n",
    "        EPMRA_.append(EPMRA)\n",
    "        EPMDEC_.append(EPMDEC)\n",
    "        PARALLAXES_.append(PLX)\n",
    "        \n",
    "        Picrs=np.array([float(-np.sin(Ra)),float(np.cos(Ra)),0])\n",
    "        Qicrs=np.array([float(-np.cos(Ra)*np.sin(DEC)),float(-np.sin(Ra)*np.sin(DEC)),float(np.cos(DEC))])\n",
    "        Pgal=np.array([float(-np.sin(L)),float(np.cos(L)),0])\n",
    "        Qgal=np.array([float(-np.cos(L)*np.sin(B)),float(-np.sin(L)*np.sin(B)),float(np.cos(B))])\n",
    "        icrs=PMRA*np.cos(DEC)*Picrs+PMDEC*Qicrs\n",
    "        GAL = np.dot(T,icrs)\n",
    "        pmL=np.dot(Pgal.transpose(),GAL)/np.cos(B)\n",
    "        pmB=np.dot(Qgal.transpose(),GAL)\n",
    "        PML.append(pmL)\n",
    "        PMB.append(pmB)\n",
    "        \n",
    "        vL=(k*Dcluster*pmL)/1000\n",
    "        vB=(k*Dcluster*pmB)/1000\n",
    "        \n",
    "        #print(idx)\n",
    "        m_true2 = [vL,vB]\n",
    "        zp = np.arange(-100., 100., 1.)\n",
    "        \n",
    "        ndim, nwalkers = 3, 50\n",
    "        pos1 = [np.array([np.random.choice(zp)+1000./PLX,np.random.choice(zp)+m_true2[0],np.random.choice(zp)+m_true2[1]]) for i in range(nwalkers)]\n",
    "        sampler1 = emcee.EnsembleSampler(nwalkers, ndim, lnprobV, args=(PLX, EPLX, PMRA, PMDEC, EPMRA, EPMDEC, DEC,  Pgal, Qgal, Picrs, Qicrs))\n",
    "        sampler1.run_mcmc(pos1, 500, rstate0=np.random.get_state())   \n",
    "        burnin = 200\n",
    "        samples1 = sampler1.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "        \n",
    "        m_mcmc4 = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                                     zip(*np.percentile(samples1, [16, 50, 84],\n",
    "                                                        axis=0))))[1]\n",
    "        \n",
    "        m_mcmc5 = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                                     zip(*np.percentile(samples1, [16, 50, 84],\n",
    "                                                        axis=0))))[2]\n",
    "            \n",
    "        #print(m_mcmc4)\n",
    "        #print(m_mcmc5)\n",
    "        \n",
    "        vLcorr.append(m_mcmc4[0]-RVc50*np.cos(np.deg2rad(Bc))*np.sin(np.deg2rad(Lc-l[idx])))\n",
    "        vBcorr.append(m_mcmc5[0]-RVc50*(np.sin(np.deg2rad(Bc))*np.cos(np.deg2rad(b[idx]))-np.sin(np.deg2rad(b[idx]))*np.cos(np.deg2rad(Bc))*np.cos(np.deg2rad(Lc-l[idx]))))\n",
    "        vLcorr_p.append(np.sqrt(m_mcmc4[1]**2+((RVc84-RVc50)*np.cos(np.deg2rad(Bc))*np.sin(np.deg2rad(Lc-l[idx])))**2))\n",
    "        vBcorr_p.append(np.sqrt(m_mcmc5[1]**2+((RVc84-RVc50)*(np.sin(np.deg2rad(Bc))*np.cos(np.deg2rad(b[idx]))-np.sin(np.deg2rad(b[idx]))*np.cos(np.deg2rad(Bc))*np.cos(np.deg2rad(Lc-l[idx]))))**2))\n",
    "        vLcorr_n.append(np.sqrt(m_mcmc4[2]**2+((RVc50-RVc16)*np.cos(np.deg2rad(Bc))*np.sin(np.deg2rad(Lc-l[idx])))**2))\n",
    "        vBcorr_n.append(np.sqrt(m_mcmc5[2]**2+((RVc50-RVc16)*(np.sin(np.deg2rad(Bc))*np.cos(np.deg2rad(b[idx]))-np.sin(np.deg2rad(b[idx]))*np.cos(np.deg2rad(Bc))*np.cos(np.deg2rad(Lc-l[idx]))))**2))\n",
    "\n",
    "\n",
    "vLcorr=np.asarray(vLcorr)\n",
    "vBcorr=np.asarray(vBcorr)\n",
    "vLcorr_p=np.asarray(vLcorr_p)\n",
    "vBcorr_p=np.asarray(vBcorr_p)\n",
    "vLcorr_n=np.asarray(vLcorr_n)\n",
    "vBcorr_n=np.asarray(vBcorr_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e30970e-74e3-426d-8a53-5a98a1baf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### You can estimate the cluster central tangential velocities by using the median, as well as estimate the uncertainty on the median values themselves\n",
    "\n",
    "medianvL=[]\n",
    "medianvB=[]\n",
    "n=0\n",
    "while n<10000:\n",
    "    a=np.random.normal(0, 1, size=(1,len(vLcorr))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), vLcorr_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), vLcorr_n)]\n",
    "    vLcorre = [i + j for i, j in zip(pos, neg)]\n",
    "    medianvL.append(np.median(vLcorr+vLcorre))\n",
    "    a=np.random.normal(0, 1, size=(1,len(vBcorr))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), vBcorr_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), vBcorr_n)]\n",
    "    vBcorre = [i + j for i, j in zip(pos, neg)]\n",
    "    medianvB.append(np.median(vBcorr+vBcorre))\n",
    "    n+=1\n",
    "    \n",
    "vLc16, vLc50, vLc84 = np.percentile(np.sort(medianvL), [16, 50, 84])\n",
    "vBc16, vBc50, vBc84 = np.percentile(np.sort(medianvB), [16, 50, 84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff4622d2-f765-49e7-818e-5e1926d68470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansion Velocity 2D = -0.522⁺0.167₋0.165 km/s\n",
      "Rotation Velocity 2D  = 1.162⁺0.242₋0.248 km/s\n"
     ]
    }
   ],
   "source": [
    "#### This bit separates the velocities into expansion and rotation components, so we can calculate the average expansion and rotation velocities\n",
    "\n",
    "\n",
    "vLx =[]\n",
    "vBx =[]\n",
    "vLr =[]\n",
    "vBr =[]\n",
    "vLxp =[]\n",
    "vBxp =[]\n",
    "vLrp =[]\n",
    "vBrp =[]\n",
    "vLxn =[]\n",
    "vBxn =[]\n",
    "vLrn =[]\n",
    "vBrn =[]\n",
    "vLxe =[]\n",
    "vBxe =[]\n",
    "vLre =[]\n",
    "vBre =[]\n",
    "RadD4=[]\n",
    "RadD4_p=[]\n",
    "RadD4_n=[]\n",
    "RadD4_e=[]\n",
    "RadV4=[]\n",
    "RadV4_p=[]\n",
    "RadV4_n=[]\n",
    "RadV4_e=[]\n",
    "RotV4=[]\n",
    "RotV4_p=[]\n",
    "RotV4_n=[]\n",
    "RotV4_e=[]\n",
    "\n",
    "RadVun4=[]\n",
    "RadVun4_p=[]\n",
    "RadVun4_n=[]\n",
    "RadVun4_e=[]\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(0,len(l)):\n",
    "    Langle = np.arctan2(b[idx]-Bc,(l[idx]-Lc)*(np.cos(np.deg2rad(Bc))))\n",
    "    vLex=[]\n",
    "    vBex=[]\n",
    "    vLro=[]\n",
    "    vBro=[]\n",
    "    RadDist=[]\n",
    "    RadVel=[]\n",
    "    RadVelun=[]\n",
    "    RotVel=[]\n",
    "    X5=[]\n",
    "    Y5=[]\n",
    "    U5=[]\n",
    "    V5=[]\n",
    "    n=0\n",
    "    while n<1000:\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vLcorr_p[idx])\n",
    "        neg = a.clip(max=0)*(vLcorr_n[idx])\n",
    "        vLcorre = pos+neg\n",
    "        vLcorridx = vLcorr[idx]+vLcorre\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vBcorr_p[idx])\n",
    "        neg = a.clip(max=0)*(vBcorr_n[idx])\n",
    "        vBcorre = pos+neg\n",
    "        vBcorridx = vBcorr[idx]+vBcorre\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vLc84-vLc50)\n",
    "        neg = a.clip(max=0)*(vLc50-vLc16)\n",
    "        vLe = pos+neg\n",
    "        vLc = vLc50+vLe\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vBc84-vBc50)\n",
    "        neg = a.clip(max=0)*(vBc50-vBc16)\n",
    "        vBe = pos+neg\n",
    "        vBc = vBc50+vBe\n",
    "        \n",
    "        #### Option to also include uncertainty on the cluster distance #####\n",
    "        \n",
    "        # a=np.random.normal(0, 1, size=(1,1)) \n",
    "        # pos = a.clip(0)*(Dcluster_bs84-Dcluster_bs50)\n",
    "        # neg = a.clip(max=0)*(Dcluster_bs50-Dcluster_bs16)\n",
    "        # Dclustere = pos+neg\n",
    "        # Dclusterc = Dcluster_bs50+Dclustere\n",
    "        n+=1\n",
    "        \n",
    "        \n",
    "        vLangle=np.arctan2(vBcorridx-vBc,(vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))\n",
    "        Xangle=Langle-vLangle\n",
    "        vLex.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.cos(Xangle)*np.cos(Langle)+vLc)\n",
    "        vBex.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.cos(Xangle)*np.sin(Langle)+vBc)\n",
    "        vLro.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.sin(Xangle)*np.sin(Langle)+vLc)\n",
    "        vBro.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.sin(Xangle)*-np.cos(Langle)+vBc)  \n",
    "        \n",
    "        \n",
    "        r=np.sqrt(((l[idx]-Lc)*(np.cos(np.deg2rad(Bc))))**2+(b[idx]-Bc)**2)\n",
    "        rho = np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.cos(Xangle)#*np.cos(Dangle) #Should this be multiplied by *np.cos(Dangle) for the 1d expansion analysis?\n",
    "        RadDist.append(np.tan(np.deg2rad(r))* Dcluster) #Dclusterc)  #Converted to pcs using the cluster distance\n",
    "        RadVel.append(rho)\n",
    "        RotVel.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.sin(Xangle))#*np.cos(Dangle))\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    vL16, vL50, vL84 = np.percentile(np.sort(vLex), [16, 50, 84])\n",
    "    vB16, vB50, vB84 = np.percentile(np.sort(vBex), [16, 50, 84])\n",
    "    vLx.append(vL50)\n",
    "    vLxp.append(vL84-vL50)\n",
    "    vLxn.append(vL50-vL16)\n",
    "    vLxe.append((vL84-vL16)/2)\n",
    "    vBx.append(vB50)\n",
    "    vBxp.append(vB84-vB50)\n",
    "    vBxn.append(vB50-vB16)\n",
    "    vBxe.append((vB84-vB16)/2)\n",
    "    \n",
    "    \n",
    "    vL16, vL50, vL84 = np.percentile(np.sort(vLro), [16, 50, 84])\n",
    "    vB16, vB50, vB84 = np.percentile(np.sort(vBro), [16, 50, 84])\n",
    "    vLr.append(vL50)\n",
    "    vLrp.append(vL84-vL50)\n",
    "    vLrn.append(vL50-vL16)\n",
    "    vLre.append((vL84-vL16)/2)\n",
    "    vBr.append(vB50)\n",
    "    vBrp.append(vB84-vB50)\n",
    "    vBrn.append(vB50-vB16)\n",
    "    vBre.append((vB84-vB16)/2)\n",
    "    \n",
    "    RD16, RD50, RD84 = np.percentile(RadDist, [16, 50, 84])\n",
    "    RV16, RV50, RV84 = np.percentile(RadVel, [16, 50, 84])\n",
    "    RotV16, RotV50, RotV84 = np.percentile(RotVel, [16, 50, 84])\n",
    "    RadD4.append(RD50)\n",
    "    RadD4_p.append(RD84-RD50)\n",
    "    RadD4_n.append(RD50-RD16)\n",
    "    RadD4_e.append((RD84-RD16)/2)\n",
    "    RadV4.append(RV50)\n",
    "    RadV4_p.append(RV84-RV50)\n",
    "    RadV4_n.append(RV50-RV16)\n",
    "    RadV4_e.append((RV84-RV16)/2)\n",
    "    RadDerr4 = [RadD4_n,RadD4_p]\n",
    "    RadVerr4 = [RadV4_n,RadV4_p]\n",
    "    RotV4.append(RotV50)\n",
    "    RotV4_p.append(RotV84-RotV50)\n",
    "    RotV4_n.append(RotV50-RotV16)\n",
    "    RotV4_e.append((RotV84-RotV16)/2)\n",
    "    RotVerr4 = [RotV4_n,RotV4_p]\n",
    "    \n",
    "\n",
    "    \n",
    "vLx =np.asarray(vLx)\n",
    "vBx =np.asarray(vBx)\n",
    "vLr =np.asarray(vLr)\n",
    "vBr =np.asarray(vBr)\n",
    "vLxp =np.asarray(vLxp)\n",
    "vBxp =np.asarray(vBxp)\n",
    "vLrp =np.asarray(vLrp)\n",
    "vBrp =np.asarray(vBrp)\n",
    "vLxn =np.asarray(vLxn)\n",
    "vBxn =np.asarray(vBxn)\n",
    "vLrn =np.asarray(vLrn)\n",
    "vBrn =np.asarray(vBrn)\n",
    "vLxe =np.asarray(vLxe)\n",
    "vBxe =np.asarray(vBxe)\n",
    "vLre =np.asarray(vLre)\n",
    "vBre =np.asarray(vBre)\n",
    "\n",
    "RadD4=np.asarray(RadD4)\n",
    "RadD4_p=np.asarray(RadD4_p)\n",
    "RadD4_n=np.asarray(RadD4_n)\n",
    "RadV4=np.asarray(RadV4)\n",
    "RadV4_p=np.asarray(RadV4_p)\n",
    "RadV4_n=np.asarray(RadV4_n)\n",
    "RotV4=np.asarray(RotV4)\n",
    "RotV4_p=np.asarray(RotV4_p)\n",
    "RotV4_n=np.asarray(RotV4_n)\n",
    "\n",
    "ExpV=[]\n",
    "n=0\n",
    "while n<100000:\n",
    "    a=np.random.normal(0, 1, size=(1,len(RadV4))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), RadV4_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), RadV4_n)]\n",
    "    RadV4e = [i + j for i, j in zip(pos, neg)]\n",
    "    ExpV.append(np.median(RadV4+RadV4e))\n",
    "    n+=1\n",
    "    \n",
    "ExpV16, ExpV50, ExpV84 = np.percentile(np.sort(ExpV), [16, 50, 84])\n",
    "\n",
    "RotV=[]\n",
    "n=0\n",
    "while n<100000:\n",
    "    a=np.random.normal(0, 1, size=(1,len(RotV4))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), RotV4_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), RotV4_n)]\n",
    "    RotV4e = [i + j for i, j in zip(pos, neg)]\n",
    "    RotV.append(np.median(RotV4+RotV4e))\n",
    "    n+=1\n",
    "    \n",
    "RotV16, RotV50, RotV84 = np.percentile(np.sort(RotV), [16, 50, 84])\n",
    "\n",
    "print(f\"Expansion Velocity 2D = {ExpV50:.3f}⁺{ExpV84 - ExpV50:.3f}₋{ExpV50 - ExpV16:.3f} km/s\")\n",
    "print(f\"Rotation Velocity 2D  = {RotV50:.3f}⁺{RotV84 - RotV50:.3f}₋{RotV50 - RotV16:.3f} km/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa637c77-1f1e-4f89-8f8d-55a55c163a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now the code to calculate closest approach to the cluster center, traceback time, etc. ####\n",
    "\n",
    "KinAge2D=[]\n",
    "PA=[]\n",
    "PA2=[]\n",
    "KinAge2D_CA=[]\n",
    "CA=[]\n",
    "KinAge2D_p=[]\n",
    "PA_p=[]\n",
    "PA2_p=[]\n",
    "KinAge2D_CA_p=[]\n",
    "CA_p=[]\n",
    "KinAge2D_n=[]\n",
    "PA_n=[]\n",
    "PA2_n=[]\n",
    "KinAge2D_CA_n=[]\n",
    "CA_n=[]\n",
    "ANGLE2=[]\n",
    "ANGLE2_p=[]\n",
    "ANGLE2_n=[]\n",
    "RadD4_2=[]\n",
    "CApc=[]\n",
    "CApc_p=[]\n",
    "CApc_n=[]\n",
    "l_=[]\n",
    "b_=[]\n",
    "TBDistance=[]\n",
    "TBDistance_p=[]\n",
    "TBDistance_n=[]\n",
    "vLcorr__=[]\n",
    "vBcorr__=[]\n",
    "vLcorr__p=[]\n",
    "vBcorr__p=[]\n",
    "vLcorr__n=[]\n",
    "vBcorr__n=[]\n",
    "\n",
    "for idx in range(0,len(RadD4)):\n",
    "    positionAngle=(np.rad2deg(np.arctan2((b[idx]-Bc),(l[idx]-Lc)*np.cos(np.deg2rad(Bc)))))\n",
    "    PA2.append(positionAngle)\n",
    "    if RadD4[idx]/RadV4[idx] >0: #### Selects only stars moving outwards for the traceback ####\n",
    "        traceback_indices.append(idx)\n",
    "        RadD4_2.append(RadD4[idx])\n",
    "        KinAge2D__=[]\n",
    "        PA__=[]\n",
    "        KinAge2D_CA__=[]\n",
    "        KinAge2D_CA_ct__=[]\n",
    "        CA__=[]\n",
    "        ANGLE2__=[]\n",
    "        CApc__=[]\n",
    "        TBDistance__=[]\n",
    "        vLcorr__.append(vLcorr[idx])\n",
    "        vBcorr__.append(vBcorr[idx])\n",
    "        vLcorr__p.append(vLcorr_p[idx])\n",
    "        vBcorr__p.append(vBcorr_p[idx])\n",
    "        vLcorr__n.append(vLcorr_n[idx])\n",
    "        vBcorr__n.append(vBcorr_n[idx])\n",
    "        n=0\n",
    "        while n<1000:\n",
    "            a=np.random.normal(0, 1, size=(1,1)) \n",
    "            pos = a.clip(0)*(vLcorr_p[idx])\n",
    "            neg = a.clip(max=0)*(vLcorr_n[idx])\n",
    "            vLcorre = pos+neg\n",
    "            vLcorridx = vLcorr[idx]+vLcorre\n",
    "            a=np.random.normal(0, 1, size=(1,1)) \n",
    "            pos = a.clip(0)*(vBcorr_p[idx])\n",
    "            neg = a.clip(max=0)*(vBcorr_n[idx])\n",
    "            vBcorre = pos+neg\n",
    "            vBcorridx = vBcorr[idx]+vBcorre\n",
    "            a=np.random.normal(0, 1, size=(1,1)) \n",
    "            pos = a.clip(0)*(vLc84-vLc50)\n",
    "            neg = a.clip(max=0)*(vLc50-vLc16)\n",
    "            vLe = pos+neg\n",
    "            vLc = vLc50+vLe\n",
    "            a=np.random.normal(0, 1, size=(1,1)) \n",
    "            pos = a.clip(0)*(vBc84-vBc50)\n",
    "            neg = a.clip(max=0)*(vBc50-vBc16)\n",
    "            vBe = pos+neg\n",
    "            vBc = vBc50+vBe\n",
    "            \n",
    "            #### Option to also include uncertainty on the cluster distance #####\n",
    "            \n",
    "            # a=np.random.normal(0, 1, size=(1,1)) \n",
    "            # pos = a.clip(0)*(Dcluster84-Dcluster50)\n",
    "            # neg = a.clip(max=0)*(Dcluster50-Dcluster16)\n",
    "            # Dclustere = pos+neg\n",
    "            # Dclusterc = Dcluster50+Dclustere\n",
    "            \n",
    "            a=np.random.normal(0, 1, size=(1,1)) \n",
    "            pos = a.clip(0)*(RadD4_p[idx])\n",
    "            neg = a.clip(max=0)*(RadD4_n[idx])\n",
    "            RadD4e = pos+neg\n",
    "            RadD4idx = RadD4[idx]+RadD4e\n",
    "            a=np.random.normal(0, 1, size=(1,1)) \n",
    "            pos = a.clip(0)*(RadV4_p[idx])\n",
    "            neg = a.clip(max=0)*(RadV4_n[idx])\n",
    "            RadV4e = pos+neg\n",
    "            RadV4idx = RadV4[idx]+RadV4e\n",
    "            n+=1\n",
    "            \n",
    "            KinAge2D__.append((1/1.023)*RadD4idx/RadV4idx)\n",
    "            PA__.append(positionAngle)\n",
    "            a_CA=((vBcorridx-vBc)/((vLcorridx-vLc)*np.cos(np.deg2rad(Bc))))\n",
    "            b_CA=-1\n",
    "            c_CA=b[idx]-Bc - ((vBcorridx-vBc)/((vLcorridx-vLc)*np.cos(np.deg2rad(Bc))))*(l[idx]-Lc)*np.cos(np.deg2rad(Bc))\n",
    "            d_CA=np.abs(c_CA)/np.sqrt(a_CA**2+b_CA**2)\n",
    "            CA__.append(d_CA) \n",
    "            DistanceTravelled=np.sqrt((b[idx]-Bc)**2+(l[idx]-Lc)**2-d_CA**2)\n",
    "            TBDistance__.append(DistanceTravelled)\n",
    "            VelTravelled=np.sqrt((vBcorridx-vBc)**2+((vLcorridx-vLc)*np.cos(np.deg2rad(Bc)))**2)\n",
    "            \n",
    "            CApc__.append((np.tan(np.deg2rad(d_CA))*Dcluster))  # Dclusterc))\n",
    "            KinAge2D_CA__.append((1/1.023)*(np.tan(np.deg2rad(DistanceTravelled))*Dcluster)/VelTravelled) # Dclusterc)/VelTravelled)\n",
    "            pmAngle=(np.rad2deg(np.arctan2((vBcorridx-vBc),(vLcorridx-vLc)*np.cos(np.deg2rad(Bc)))))\n",
    "            if pmAngle-positionAngle > 180:\n",
    "                ANGLE2__.append(pmAngle-positionAngle-180)\n",
    "            elif pmAngle-positionAngle < -180:\n",
    "                ANGLE2__.append(pmAngle-positionAngle+180)\n",
    "            else:\n",
    "                ANGLE2__.append(pmAngle-positionAngle)\n",
    "            \n",
    "        \n",
    "        KinAge2D16, KinAge2D50, KinAge2D84 = np.percentile(np.sort(KinAge2D__), [16, 50, 84])\n",
    "        PA16, PA50, PA84 = np.percentile(np.sort(PA__), [16, 50, 84])\n",
    "        CA16, CA50, CA84 = np.percentile(np.sort(CA__), [16, 50, 84])\n",
    "        KinAge2D_CA16, KinAge2D_CA50, KinAge2D_CA84 = np.percentile(np.sort(KinAge2D_CA__), [16, 50, 84])\n",
    "        ANGLE216, ANGLE250, ANGLE284 = np.percentile(np.sort(ANGLE2__), [16, 50, 84])\n",
    "        CApc16, CApc50, CApc84 = np.percentile(np.sort(CApc__), [16, 50, 84])\n",
    "        TBDistance__16, TBDistance__50, TBDistance__84 = np.percentile(np.sort(TBDistance__), [16, 50, 84])\n",
    "        \n",
    "        KinAge2D.append(KinAge2D50)\n",
    "        KinAge2D_p.append(KinAge2D84-KinAge2D50)\n",
    "        KinAge2D_n.append(KinAge2D50-KinAge2D16)\n",
    "        PA.append(PA50)\n",
    "        PA_p.append(PA84-PA50)\n",
    "        PA_n.append(PA50-PA16)\n",
    "        CA.append(CA50) \n",
    "        CA_p.append(CA84-CA50)\n",
    "        CA_n.append(CA50-CA16)\n",
    "        CApc.append(CApc50) \n",
    "        CApc_p.append(CApc84-CApc50)\n",
    "        CApc_n.append(CApc50-CApc16)\n",
    "        KinAge2D_CA.append(KinAge2D_CA50)\n",
    "        KinAge2D_CA_p.append(KinAge2D_CA84-KinAge2D_CA50)\n",
    "        KinAge2D_CA_n.append(KinAge2D_CA50-KinAge2D_CA16)\n",
    "        ANGLE2.append(ANGLE250)\n",
    "        ANGLE2_p.append(ANGLE284-ANGLE250)\n",
    "        ANGLE2_n.append(ANGLE250-ANGLE216)\n",
    "        l_.append(l[idx])\n",
    "        b_.append(b[idx])\n",
    "        TBDistance.append(TBDistance__50)\n",
    "        TBDistance_p.append(TBDistance__84-TBDistance__50)\n",
    "        TBDistance_n.append(TBDistance__50-TBDistance__16)\n",
    "\n",
    "KinAge2D_all = full(N, nan)\n",
    "KinAge2D_p_all = full(N, nan)\n",
    "KinAge2D_n_all = full(N, nan)\n",
    "PA_all = full(N, nan)\n",
    "PA_p_all = full(N, nan)\n",
    "PA_n_all = full(N, nan)\n",
    "CA_all = full(N, nan)\n",
    "CA_p_all = full(N, nan)\n",
    "CA_n_all = full(N, nan)\n",
    "CApc_all = full(N, nan)\n",
    "CApc_p_all = full(N, nan)\n",
    "CApc_n_all = full(N, nan)\n",
    "KinAge2D_CA_all = full(N, nan)\n",
    "KinAge2D_CA_p_all = full(N, nan)\n",
    "KinAge2D_CA_n_all = full(N, nan)\n",
    "ANGLE2_all = full(N, nan)\n",
    "ANGLE2_p_all = full(N, nan)\n",
    "ANGLE2_n_all = full(N, nan)\n",
    "TBDistance_all = full(N, nan)\n",
    "TBDistance_p_all = full(N, nan)\n",
    "TBDistance_n_all = full(N, nan)\n",
    "\n",
    "for i, idx in enumerate(traceback_indices):\n",
    "    KinAge2D_all[idx] = KinAge2D[i]\n",
    "    KinAge2D_p_all[idx] = KinAge2D_p[i]\n",
    "    KinAge2D_n_all[idx] = KinAge2D_n[i]\n",
    "    PA_all[idx] = PA[i]\n",
    "    PA_p_all[idx] = PA_p[i]\n",
    "    PA_n_all[idx] = PA_n[i]\n",
    "    CA_all[idx] = CA[i]\n",
    "    CA_p_all[idx] = CA_p[i]\n",
    "    CA_n_all[idx] = CA_n[i]\n",
    "    CApc_all[idx] = CApc[i]\n",
    "    CApc_p_all[idx] = CApc_p[i]\n",
    "    CApc_n_all[idx] = CApc_n[i]\n",
    "    KinAge2D_CA_all[idx] = KinAge2D_CA[i]\n",
    "    KinAge2D_CA_p_all[idx] = KinAge2D_CA_p[i]\n",
    "    KinAge2D_CA_n_all[idx] = KinAge2D_CA_n[i]\n",
    "    ANGLE2_all[idx] = ANGLE2[i]\n",
    "    ANGLE2_p_all[idx] = ANGLE2_p[i]\n",
    "    ANGLE2_n_all[idx] = ANGLE2_n[i]\n",
    "    TBDistance_all[idx] = TBDistance[i]\n",
    "    TBDistance_p_all[idx] = TBDistance_p[i]\n",
    "    TBDistance_n_all[idx] = TBDistance_n[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f678663-d5e8-4f43-9853-d85cf1539d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = Table(\n",
    "    [\n",
    "        ra, dec, l, b,\n",
    "        vLcorr, vLcorr_p, vLcorr_n,\n",
    "        vBcorr, vBcorr_p, vBcorr_n,\n",
    "        vLx, vLxp, vLxn, vLxe,\n",
    "        vBx, vBxp, vBxn, vBxe,\n",
    "        vLr, vLrp, vLrn, vLre,\n",
    "        vBr, vBrp, vBrn, vBre,\n",
    "        RadD4, RadD4_p, RadD4_n,\n",
    "        RadV4, RadV4_p, RadV4_n,\n",
    "        RotV4, RotV4_p, RotV4_n,\n",
    "        KinAge2D_all, KinAge2D_p_all, KinAge2D_n_all,\n",
    "        PA_all, PA_p_all, PA_n_all,\n",
    "        CA_all, CA_p_all, CA_n_all,\n",
    "        CApc_all, CApc_p_all, CApc_n_all,\n",
    "        KinAge2D_CA_all, KinAge2D_CA_p_all, KinAge2D_CA_n_all,\n",
    "        ANGLE2_all, ANGLE2_p_all, ANGLE2_n_all,\n",
    "        TBDistance_all, TBDistance_p_all, TBDistance_n_all\n",
    "    ],\n",
    "    names=[\n",
    "        \"ra\", \"dec\", \"l\", \"b\",\n",
    "        \"vLcorr\", \"vLcorr_p\", \"vLcorr_n\", \n",
    "        \"vBcorr\", \"vBcorr_p\", \"vBcorr_n\", \n",
    "        \"vLx\", \"vLx_p\", \"vLx_n\", \"vLx_e\",\n",
    "        \"vBx\", \"vBx_p\", \"vBx_n\", \"vBx_e\",\n",
    "        \"vLr\", \"vLr_p\", \"vLr_n\", \"vLr_e\",\n",
    "        \"vBr\", \"vBr_p\", \"vBr_n\", \"vBr_e\",\n",
    "        \"RadD4\", \"RadD4_p\", \"RadD4_n\",\n",
    "        \"RadV4\", \"RadV4_p\", \"RadV4_n\",\n",
    "        \"RotV4\", \"RotV4_p\", \"RotV4_n\",\n",
    "        \"KinAge2D\", \"KinAge2D_p\", \"KinAge2D_n\",\n",
    "        \"PA\", \"PA_p\", \"PA_n\",\n",
    "        \"CA\", \"CA_p\", \"CA_n\",\n",
    "        \"CApc\", \"CApc_p\", \"CApc_n\",\n",
    "        \"KinAge2D_CA\", \"KinAge2D_CA_p\", \"KinAge2D_CA_n\",\n",
    "        \"ANGLE2\", \"ANGLE2_p\", \"ANGLE2_n\",\n",
    "        \"TBDistance\", \"TBDistance_p\", \"TBDistance_n\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Optional: units and metadata -------------------------------------\n",
    "tab['ra'].unit  = 'deg'\n",
    "tab['dec'].unit = 'deg'\n",
    "tab.meta['comment'] = \"Full cluster kinematic/traceback catalogue\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Save in your preferred formats -------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "tab.write(\"cluster_kinematic_traceback.fits\", format=\"fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb42e9a-bf6f-4289-961b-72c8a11c42f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de05fe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cluster average vLcorr : -48.89 [km/s]\n",
      " cluster average vBcorr : -9.74 [km/s]\n"
     ]
    }
   ],
   "source": [
    "hdul = fits.open('RCW_36.fits')\n",
    "hdul = hdul[1].data\n",
    "t = Table(hdul)\n",
    "\n",
    "ra = t['RA']\n",
    "dec = t['DEC']\n",
    "l = t['l']\n",
    "b = t['b']\n",
    "Plx = t['parallax']\n",
    "ePlx = t['parallax_error']\n",
    "pmRA = t['pmra']\n",
    "pmDE = t['pmdec']\n",
    "epmRA = t['pmra_error']\n",
    "epmDE = t['pmdec_error']\n",
    "\n",
    "mask = ~np.isnan(ra) & ~np.isnan(dec) & ~np.isnan(l) & ~np.isnan(b) & ~np.isnan(Plx) & ~np.isnan(ePlx) & ~np.isnan(pmRA) & ~np.isnan(pmDE) & ~np.isnan(epmRA) & ~np.isnan(epmDE)\n",
    "\n",
    "ra = ra[mask]\n",
    "dec = dec[mask]\n",
    "l = l[mask]\n",
    "b = b[mask]\n",
    "Plx = Plx[mask]\n",
    "ePlx = ePlx[mask]\n",
    "pmRA = pmRA[mask]\n",
    "pmDE = pmDE[mask]\n",
    "epmRA = epmRA[mask]\n",
    "epmDE = epmDE[mask]\n",
    "\n",
    "\n",
    "vLcorr=[]\n",
    "vBcorr=[]\n",
    "vLcorr_p=[]\n",
    "vBcorr_p=[]\n",
    "vLcorr_n=[]\n",
    "vBcorr_n=[]\n",
    "PMRA_=[]\n",
    "PMDEC_=[]\n",
    "EPMRA_=[]\n",
    "EPMDEC_=[]\n",
    "PARALLAXES_=[]\n",
    "PML=[]\n",
    "PMB=[]\n",
    "\n",
    "for idx in range(0,len(ra)):\n",
    "    \n",
    "    #################### Here you may choose only to perform the transformation on sources with reliable astrometry with an 'if' statement  #############\n",
    "    \n",
    "    # if ruwe[idx] < 1.4 and prob[idx]>0.89 and CGcluster[idx] == name and np.isnan(Gmag[idx])==False:\n",
    "        Ra = np.deg2rad(ra[idx])\n",
    "        DEC = np.deg2rad(dec[idx])\n",
    "        L = np.deg2rad(l[idx])\n",
    "        B = np.deg2rad(b[idx])\n",
    "        PLX = Plx[idx]\n",
    "        EPLX = ePlx[idx]\n",
    "        PMRA = pmRA[idx]\n",
    "        PMDEC = pmDE[idx]\n",
    "        EPMRA = epmRA[idx]\n",
    "        EPMDEC = epmDE[idx]\n",
    "        PMRA_.append(PMRA)\n",
    "        PMDEC_.append(PMDEC)\n",
    "        EPMRA_.append(EPMRA)\n",
    "        EPMDEC_.append(EPMDEC)\n",
    "        PARALLAXES_.append(PLX)\n",
    "        \n",
    "        Picrs=np.array([float(-np.sin(Ra)),float(np.cos(Ra)),0])\n",
    "        Qicrs=np.array([float(-np.cos(Ra)*np.sin(DEC)),float(-np.sin(Ra)*np.sin(DEC)),float(np.cos(DEC))])\n",
    "        Pgal=np.array([float(-np.sin(L)),float(np.cos(L)),0])\n",
    "        Qgal=np.array([float(-np.cos(L)*np.sin(B)),float(-np.sin(L)*np.sin(B)),float(np.cos(B))])\n",
    "        icrs=PMRA*np.cos(DEC)*Picrs+PMDEC*Qicrs\n",
    "        GAL = np.dot(T,icrs)\n",
    "        pmL=np.dot(Pgal.transpose(),GAL)/np.cos(B)\n",
    "        pmB=np.dot(Qgal.transpose(),GAL)\n",
    "        PML.append(pmL)\n",
    "        PMB.append(pmB)\n",
    "        \n",
    "        vL=(k*Dcluster*pmL)/1000\n",
    "        vB=(k*Dcluster*pmB)/1000\n",
    "        \n",
    "        #print(idx)\n",
    "        m_true2 = [vL,vB]\n",
    "        zp = np.arange(-100., 100., 1.)\n",
    "        \n",
    "        ndim, nwalkers = 3, 50\n",
    "        pos1 = [np.array([np.random.choice(zp)+1000./PLX,np.random.choice(zp)+m_true2[0],np.random.choice(zp)+m_true2[1]]) for i in range(nwalkers)]\n",
    "        sampler1 = emcee.EnsembleSampler(nwalkers, ndim, lnprobV, args=(PLX, EPLX, PMRA, PMDEC, EPMRA, EPMDEC, DEC,  Pgal, Qgal, Picrs, Qicrs))\n",
    "        sampler1.run_mcmc(pos1, 500, rstate0=np.random.get_state())   \n",
    "        burnin = 200\n",
    "        samples1 = sampler1.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "        \n",
    "        m_mcmc4 = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                                     zip(*np.percentile(samples1, [16, 50, 84],\n",
    "                                                        axis=0))))[1]\n",
    "        \n",
    "        m_mcmc5 = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                                     zip(*np.percentile(samples1, [16, 50, 84],\n",
    "                                                        axis=0))))[2]\n",
    "            \n",
    "        #print(m_mcmc4)\n",
    "        #print(m_mcmc5)\n",
    "        \n",
    "        vLcorr.append(m_mcmc4[0]-RVc50*np.cos(np.deg2rad(Bc))*np.sin(np.deg2rad(Lc-l[idx])))\n",
    "        vBcorr.append(m_mcmc5[0]-RVc50*(np.sin(np.deg2rad(Bc))*np.cos(np.deg2rad(b[idx]))-np.sin(np.deg2rad(b[idx]))*np.cos(np.deg2rad(Bc))*np.cos(np.deg2rad(Lc-l[idx]))))\n",
    "        vLcorr_p.append(np.sqrt(m_mcmc4[1]**2+((RVc84-RVc50)*np.cos(np.deg2rad(Bc))*np.sin(np.deg2rad(Lc-l[idx])))**2))\n",
    "        vBcorr_p.append(np.sqrt(m_mcmc5[1]**2+((RVc84-RVc50)*(np.sin(np.deg2rad(Bc))*np.cos(np.deg2rad(b[idx]))-np.sin(np.deg2rad(b[idx]))*np.cos(np.deg2rad(Bc))*np.cos(np.deg2rad(Lc-l[idx]))))**2))\n",
    "        vLcorr_n.append(np.sqrt(m_mcmc4[2]**2+((RVc50-RVc16)*np.cos(np.deg2rad(Bc))*np.sin(np.deg2rad(Lc-l[idx])))**2))\n",
    "        vBcorr_n.append(np.sqrt(m_mcmc5[2]**2+((RVc50-RVc16)*(np.sin(np.deg2rad(Bc))*np.cos(np.deg2rad(b[idx]))-np.sin(np.deg2rad(b[idx]))*np.cos(np.deg2rad(Bc))*np.cos(np.deg2rad(Lc-l[idx]))))**2))\n",
    "\n",
    "\n",
    "vLcorr=np.asarray(vLcorr)\n",
    "vBcorr=np.asarray(vBcorr)\n",
    "vLcorr_p=np.asarray(vLcorr_p)\n",
    "vBcorr_p=np.asarray(vBcorr_p)\n",
    "vLcorr_n=np.asarray(vLcorr_n)\n",
    "vBcorr_n=np.asarray(vBcorr_n)\n",
    "\n",
    "clustervL = np.median(vLcorr)\n",
    "clustervB = np.median(vBcorr)\n",
    "\n",
    "print(f' cluster average vLcorr : {clustervL:.2f} [km/s]')\n",
    "print(f' cluster average vBcorr : {clustervB:.2f} [km/s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6136145-4aef-4ba3-aa20-fc0f1c75f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### You can estimate the cluster central tangential velocities by using the median, as well as estimate the uncertainty on the median values themselves\n",
    "\n",
    "medianvL=[]\n",
    "medianvB=[]\n",
    "n=0\n",
    "while n<10000:\n",
    "    a=np.random.normal(0, 1, size=(1,len(vLcorr))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), vLcorr_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), vLcorr_n)]\n",
    "    vLcorre = [i + j for i, j in zip(pos, neg)]\n",
    "    medianvL.append(np.median(vLcorr+vLcorre))\n",
    "    a=np.random.normal(0, 1, size=(1,len(vBcorr))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), vBcorr_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), vBcorr_n)]\n",
    "    vBcorre = [i + j for i, j in zip(pos, neg)]\n",
    "    medianvB.append(np.median(vBcorr+vBcorre))\n",
    "    n+=1\n",
    "    \n",
    "vLc16, vLc50, vLc84 = np.percentile(np.sort(medianvL), [16, 50, 84])\n",
    "vBc16, vBc50, vBc84 = np.percentile(np.sort(medianvB), [16, 50, 84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "924059ab-9a1e-4f5b-80f0-a4e071eacdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansion Velocity 2D = 1.446⁺4.015₋4.409 km/s\n",
      "Rotation Velocity 2D  = -6.409⁺3.124₋3.462 km/s\n"
     ]
    }
   ],
   "source": [
    "#### This bit separates the velocities into expansion and rotation components, so we can calculate the average expansion and rotation velocities\n",
    "\n",
    "\n",
    "vLx =[]\n",
    "vBx =[]\n",
    "vLr =[]\n",
    "vBr =[]\n",
    "vLxp =[]\n",
    "vBxp =[]\n",
    "vLrp =[]\n",
    "vBrp =[]\n",
    "vLxn =[]\n",
    "vBxn =[]\n",
    "vLrn =[]\n",
    "vBrn =[]\n",
    "vLxe =[]\n",
    "vBxe =[]\n",
    "vLre =[]\n",
    "vBre =[]\n",
    "RadD4=[]\n",
    "RadD4_p=[]\n",
    "RadD4_n=[]\n",
    "RadD4_e=[]\n",
    "RadV4=[]\n",
    "RadV4_p=[]\n",
    "RadV4_n=[]\n",
    "RadV4_e=[]\n",
    "RotV4=[]\n",
    "RotV4_p=[]\n",
    "RotV4_n=[]\n",
    "RotV4_e=[]\n",
    "\n",
    "RadVun4=[]\n",
    "RadVun4_p=[]\n",
    "RadVun4_n=[]\n",
    "RadVun4_e=[]\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(0,len(l)):\n",
    "    Langle = np.arctan2(b[idx]-Bc,(l[idx]-Lc)*(np.cos(np.deg2rad(Bc))))\n",
    "    vLex=[]\n",
    "    vBex=[]\n",
    "    vLro=[]\n",
    "    vBro=[]\n",
    "    RadDist=[]\n",
    "    RadVel=[]\n",
    "    RadVelun=[]\n",
    "    RotVel=[]\n",
    "    X5=[]\n",
    "    Y5=[]\n",
    "    U5=[]\n",
    "    V5=[]\n",
    "    n=0\n",
    "    while n<1000:\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vLcorr_p[idx])\n",
    "        neg = a.clip(max=0)*(vLcorr_n[idx])\n",
    "        vLcorre = pos+neg\n",
    "        vLcorridx = vLcorr[idx]+vLcorre\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vBcorr_p[idx])\n",
    "        neg = a.clip(max=0)*(vBcorr_n[idx])\n",
    "        vBcorre = pos+neg\n",
    "        vBcorridx = vBcorr[idx]+vBcorre\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vLc84-vLc50)\n",
    "        neg = a.clip(max=0)*(vLc50-vLc16)\n",
    "        vLe = pos+neg\n",
    "        vLc = vLc50+vLe\n",
    "        a=np.random.normal(0, 1, size=(1,1)) \n",
    "        pos = a.clip(0)*(vBc84-vBc50)\n",
    "        neg = a.clip(max=0)*(vBc50-vBc16)\n",
    "        vBe = pos+neg\n",
    "        vBc = vBc50+vBe\n",
    "        \n",
    "        #### Option to also include uncertainty on the cluster distance #####\n",
    "        \n",
    "        # a=np.random.normal(0, 1, size=(1,1)) \n",
    "        # pos = a.clip(0)*(Dcluster_bs84-Dcluster_bs50)\n",
    "        # neg = a.clip(max=0)*(Dcluster_bs50-Dcluster_bs16)\n",
    "        # Dclustere = pos+neg\n",
    "        # Dclusterc = Dcluster_bs50+Dclustere\n",
    "        n+=1\n",
    "        \n",
    "        \n",
    "        vLangle=np.arctan2(vBcorridx-vBc,(vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))\n",
    "        Xangle=Langle-vLangle\n",
    "        vLex.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.cos(Xangle)*np.cos(Langle)+vLc)\n",
    "        vBex.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.cos(Xangle)*np.sin(Langle)+vBc)\n",
    "        vLro.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.sin(Xangle)*np.sin(Langle)+vLc)\n",
    "        vBro.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.sin(Xangle)*-np.cos(Langle)+vBc)  \n",
    "        \n",
    "        \n",
    "        r=np.sqrt(((l[idx]-Lc)*(np.cos(np.deg2rad(Bc))))**2+(b[idx]-Bc)**2)\n",
    "        rho = np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.cos(Xangle)#*np.cos(Dangle) #Should this be multiplied by *np.cos(Dangle) for the 1d expansion analysis?\n",
    "        RadDist.append(np.tan(np.deg2rad(r))* Dcluster) #Dclusterc)  #Converted to pcs using the cluster distance\n",
    "        RadVel.append(rho)\n",
    "        RotVel.append(np.sqrt(((vLcorridx-vLc)*(np.cos(np.deg2rad(Bc))))**2+(vBcorridx-vBc)**2)*np.sin(Xangle))#*np.cos(Dangle))\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    vL16, vL50, vL84 = np.percentile(np.sort(vLex), [16, 50, 84])\n",
    "    vB16, vB50, vB84 = np.percentile(np.sort(vBex), [16, 50, 84])\n",
    "    vLx.append(vL50)\n",
    "    vLxp.append(vL84-vL50)\n",
    "    vLxn.append(vL50-vL16)\n",
    "    vLxe.append((vL84-vL16)/2)\n",
    "    vBx.append(vB50)\n",
    "    vBxp.append(vB84-vB50)\n",
    "    vBxn.append(vB50-vB16)\n",
    "    vBxe.append((vB84-vB16)/2)\n",
    "    \n",
    "    \n",
    "    vL16, vL50, vL84 = np.percentile(np.sort(vLro), [16, 50, 84])\n",
    "    vB16, vB50, vB84 = np.percentile(np.sort(vBro), [16, 50, 84])\n",
    "    vLr.append(vL50)\n",
    "    vLrp.append(vL84-vL50)\n",
    "    vLrn.append(vL50-vL16)\n",
    "    vLre.append((vL84-vL16)/2)\n",
    "    vBr.append(vB50)\n",
    "    vBrp.append(vB84-vB50)\n",
    "    vBrn.append(vB50-vB16)\n",
    "    vBre.append((vB84-vB16)/2)\n",
    "    \n",
    "    RD16, RD50, RD84 = np.percentile(RadDist, [16, 50, 84])\n",
    "    RV16, RV50, RV84 = np.percentile(RadVel, [16, 50, 84])\n",
    "    RotV16, RotV50, RotV84 = np.percentile(RotVel, [16, 50, 84])\n",
    "    RadD4.append(RD50)\n",
    "    RadD4_p.append(RD84-RD50)\n",
    "    RadD4_n.append(RD50-RD16)\n",
    "    RadD4_e.append((RD84-RD16)/2)\n",
    "    RadV4.append(RV50)\n",
    "    RadV4_p.append(RV84-RV50)\n",
    "    RadV4_n.append(RV50-RV16)\n",
    "    RadV4_e.append((RV84-RV16)/2)\n",
    "    RadDerr4 = [RadD4_n,RadD4_p]\n",
    "    RadVerr4 = [RadV4_n,RadV4_p]\n",
    "    RotV4.append(RotV50)\n",
    "    RotV4_p.append(RotV84-RotV50)\n",
    "    RotV4_n.append(RotV50-RotV16)\n",
    "    RotV4_e.append((RotV84-RotV16)/2)\n",
    "    RotVerr4 = [RotV4_n,RotV4_p]\n",
    "    \n",
    "\n",
    "    \n",
    "vLx =np.asarray(vLx)\n",
    "vBx =np.asarray(vBx)\n",
    "vLr =np.asarray(vLr)\n",
    "vBr =np.asarray(vBr)\n",
    "vLxp =np.asarray(vLxp)\n",
    "vBxp =np.asarray(vBxp)\n",
    "vLrp =np.asarray(vLrp)\n",
    "vBrp =np.asarray(vBrp)\n",
    "vLxn =np.asarray(vLxn)\n",
    "vBxn =np.asarray(vBxn)\n",
    "vLrn =np.asarray(vLrn)\n",
    "vBrn =np.asarray(vBrn)\n",
    "vLxe =np.asarray(vLxe)\n",
    "vBxe =np.asarray(vBxe)\n",
    "vLre =np.asarray(vLre)\n",
    "vBre =np.asarray(vBre)\n",
    "\n",
    "RadD4=np.asarray(RadD4)\n",
    "RadD4_p=np.asarray(RadD4_p)\n",
    "RadD4_n=np.asarray(RadD4_n)\n",
    "RadV4=np.asarray(RadV4)\n",
    "RadV4_p=np.asarray(RadV4_p)\n",
    "RadV4_n=np.asarray(RadV4_n)\n",
    "RotV4=np.asarray(RotV4)\n",
    "RotV4_p=np.asarray(RotV4_p)\n",
    "RotV4_n=np.asarray(RotV4_n)\n",
    "\n",
    "ExpV=[]\n",
    "n=0\n",
    "while n<100000:\n",
    "    a=np.random.normal(0, 1, size=(1,len(RadV4))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), RadV4_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), RadV4_n)]\n",
    "    RadV4e = [i + j for i, j in zip(pos, neg)]\n",
    "    ExpV.append(np.median(RadV4+RadV4e))\n",
    "    n+=1\n",
    "    \n",
    "ExpV16, ExpV50, ExpV84 = np.percentile(np.sort(ExpV), [16, 50, 84])\n",
    "\n",
    "RotV=[]\n",
    "n=0\n",
    "while n<100000:\n",
    "    a=np.random.normal(0, 1, size=(1,len(RotV4))) \n",
    "    pos = [i*j for i, j in zip(a.clip(0), RotV4_p)]\n",
    "    neg = [i*j for i, j in zip(a.clip(max=0), RotV4_n)]\n",
    "    RotV4e = [i + j for i, j in zip(pos, neg)]\n",
    "    RotV.append(np.median(RotV4+RotV4e))\n",
    "    n+=1\n",
    "    \n",
    "RotV16, RotV50, RotV84 = np.percentile(np.sort(RotV), [16, 50, 84])\n",
    "\n",
    "print(f\"Expansion Velocity 2D = {ExpV50:.3f}⁺{ExpV84 - ExpV50:.3f}₋{ExpV50 - ExpV16:.3f} km/s\")\n",
    "print(f\"Rotation Velocity 2D  = {RotV50:.3f}⁺{RotV84 - RotV50:.3f}₋{RotV50 - RotV16:.3f} km/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35abe1e-e5d6-4230-8100-244e857b292c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
